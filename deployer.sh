#!/bin/bash

set -euxo pipefail

export HOME="${HOME:-/root}"
echo "ğŸ“¦ Starting Tofuhub bootstrap (non-interactive mode)..."

export DEBIAN_FRONTEND=noninteractive

### 1. Install Docker (via official script) ###
echo "ğŸ³ Installing Docker from official script..."

curl -fsSL https://get.docker.com | sh

systemctl enable docker
systemctl start docker

echo "âœ… Docker installed."

### 2. Docker Compose CLI Compatibility ###
echo "ğŸ”§ Ensuring Docker Compose CLI compatibility..."

# Handle edge case where plugin is not linked in $PATH
ln -sf /usr/libexec/docker/cli-plugins/docker-compose /usr/local/bin/docker-compose || true

docker compose version || docker-compose version

echo "âœ… Docker Compose ready."

### 3. Install Ollama ###
echo "ğŸ¦™ Installing Ollama..."

curl -fsSL https://ollama.com/install.sh | bash || echo "âš ï¸ Ollama install script may have exited nonzero"

echo "âœ… Ollama installed (or attempted)."

### 4. Test Everything ###
echo "ğŸ§ª Verifying installation..."

docker --version
docker compose version || docker-compose version
ollama --version || echo "âš ï¸ Ollama version check skipped (likely needs shell reload)"

### 5. Start Ollama server and load llama3 ###
echo "ğŸ› ï¸ Starting Ollama server in background..."
nohup ollama serve > /var/log/ollama.log 2>&1 &

echo "â³ Waiting for Ollama server to become available..."
until curl -s http://localhost:11434 > /dev/null; do
  sleep 1
done
echo "âœ… Ollama server is up!"

echo "ğŸš€ Pulling llama3 model..."
ollama run llama3 || echo "âš ï¸ Model load failed"
